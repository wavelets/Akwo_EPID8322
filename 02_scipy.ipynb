{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy\n",
    "\n",
    "The SciPy framework builds on top of the low-level NumPy framwork for multidimensional arrays, and provides a large number of higher-level scientific algorithms. Some of the topics that SciPy covers are:\n",
    "\n",
    "* Special functions ([scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html))\n",
    "* Integration ([scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html))\n",
    "* Optimization ([scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html))\n",
    "* Interpolation ([scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html))\n",
    "* Fourier Transforms ([scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html))\n",
    "* Signal Processing ([scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html))\n",
    "* Linear Algebra ([scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html))\n",
    "* Sparse Eigenvalue Problems ([scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html))\n",
    "* Statistics ([scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* Multi-dimensional image processing ([scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html))\n",
    "* File IO ([scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html))\n",
    "\n",
    "Each of these submodules provides a number of **functions and classes** that can be used to solve problems in their respective topics.\n",
    "\n",
    "In this module, we will look at how to use some of these subpackages.\n",
    "\n",
    "To access the SciPy package in a Python program, we start by importing the `scipy` module. As a shortcut, we will abbreviate `scipy` to `sp`, analogous to what we have done with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration\n",
    "\n",
    "### Numerical integration: quadrature\n",
    "\n",
    "Numerical evaluation of a function of the type\n",
    "\n",
    "$\\displaystyle \\int_a^b f(x) dx$\n",
    "\n",
    "is called *numerical quadrature*, or simply *quadature*. SciPy provides a series of functions for different kind of quadrature, for example the `quad`, `dblquad` and `tplquad` for single, double and triple integrals, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad, dblquad, tplquad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `quad` functions takes a large number of optional arguments, which can be used to fine-tune the behaviour of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple usage example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a simple function for the integrand\n",
    "def f(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lower = 0 # the lower limit of x\n",
    "x_upper = 1 # the upper limit of x\n",
    "\n",
    "val, abserr = quad(f, x_lower, x_upper)\n",
    "\n",
    "print(\"integral value = {0}, absolute error = {1}\".format(val, abserr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to pass extra arguments to integrand function we can use the `args` keyword argument. For example, consider integrating the probability distribution function (PDF) of a normal distribution. Statistical distributions and their corresponding functions are available in the `scipy.stats` submodule; the normal PDF requires two arguments, corresponding to the mean and standard deviation of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Integral of N(2, 3) over [inf, 0)\n",
    "val, abserr = quad(stats.distributions.norm.pdf, a=-np.inf, b=0, \n",
    "                   args=(2, 3))\n",
    "\n",
    "print(val, abserr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.distributions.norm.cdf(0, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in this example, we can also use infinity (positive or negative) as integral limits, as specified by the constant `inf` in the NumPy library.\n",
    "\n",
    "Higher-dimensional integration works in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def integrand(x, y):\n",
    "    return np.exp(-x**2-y**2)\n",
    "\n",
    "x_lower = 0  \n",
    "x_upper = 10\n",
    "y_lower = 0\n",
    "y_upper = 10\n",
    "\n",
    "val, abserr = dblquad(integrand, x_lower, x_upper, \n",
    "                      lambda x : y_lower, lambda x: y_upper)\n",
    "\n",
    "print(val, abserr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we passed `lambda` functions for the limits for the `y` integration, since these in general can be functions of x (though they are not here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Trapezoid rule\n",
    "\n",
    "A simple illustration of the trapezoid rule for definite integration:\n",
    "\n",
    "$$\n",
    "\\int_{a}^{b} f(x)\\, dx \\approx \\frac{1}{2} \\sum_{k=1}^{N} \\left( x_{k} - x_{k-1} \\right) \\left( f(x_{k}) + f(x_{k-1}) \\right).\n",
    "$$\n",
    "<br>\n",
    "First, we define a simple function and sample it between 0 and 10 at 200 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x-3) * (x-5) * (x-7) + 85\n",
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a region to integrate over and take only a few points in that region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = 1, 11\n",
    "xint = x[(x>=a) & (x<=b)][::30]\n",
    "yint = y[(x>=a) & (x<=b)][::30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot both the function and the area below it in the trapezoid approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(x, y, lw=2)\n",
    "plt.axis([0, 10, 0, 140])\n",
    "plt.fill_between(xint, 0, yint, facecolor='gray', alpha=0.4)\n",
    "plt.text(0.5 * (a + b), 30,r\"$\\int_a^b f(x)dx$\", \n",
    "         horizontalalignment='center', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad, trapz\n",
    "\n",
    "integral, error = quad(f, 1, 9)\n",
    "print(\"The integral is:\", integral, \"+/-\", error)\n",
    "print(\"The trapezoid approximation with\", len(xint), \"points is:\", trapz(yint, xint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra\n",
    "\n",
    "The linear algebra module contains a lot of matrix related functions, including linear equation solving, eigenvalue solvers, matrix functions (for example matrix-exponentiation), and several decompositions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear equation systems\n",
    "\n",
    "Linear equation systems of the matrix form:\n",
    "\n",
    "$A x = b$\n",
    "\n",
    "where $A$ is a matrix and $x,b$ are vectors can be solved using the `solve` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "b = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.dot(A, x) - b).round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the same with matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(3,3)\n",
    "B = np.random.rand(3,3)\n",
    "\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = solve(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "\n",
    "norm(np.dot(A, X) - B).round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalue problem for a matrix $A$:\n",
    "\n",
    "$\\displaystyle A v_n = \\lambda_n v_n$\n",
    "\n",
    "where $v_n$ are is the $n$th eigenvector and $\\lambda_n$ is the $n$th eigenvalue.\n",
    "\n",
    "To calculate eigenvalues of a matrix, use the `eigvals` and for calculating both eigenvalues and eigenvectors, use the function `eig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import eigvals, eig\n",
    "\n",
    "evals = eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evals, evecs = eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors corresponding to the $n$th eigenvalue (stored in `evals[n]`) is the $n$th *column* in `evecs`, i.e., `evecs[:,n]`. To verify this, let's try mutiplying eigenvectors with the matrix and compare to the product of the eigenvector and the eigenvalue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "np.round(norm(np.dot(A, evecs[:,n]) - evals[n] * evecs[:,n]), 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also more specialized eigensolvers, like the `eigh` for Hermitian matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the matrix inverse\n",
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# determinant\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# norms of various orders\n",
    "np.linalg.norm(A, ord=2), np.linalg.norm(A, ord=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrices\n",
    "\n",
    "Sparse matrices are often useful in numerical simulations dealing with large systems, if the problem can be described in matrix form where the matrices or vectors mostly contains zeros. Scipy has a good support for sparse matrices, with basic linear algebra operations (such as equation solving, eigenvalue calculations, etc).\n",
    "\n",
    "There are many possible strategies for storing sparse matrices in an efficient way. Some of the most common are the so-called coordinate form (COO), list of list (LIL) form,  and compressed-sparse column CSC (and row, CSR). Each format has some advantanges and disadvantages. Most computational algorithms (equation solving, matrix-matrix multiplication, etc) can be efficiently implemented using CSR or CSC formats, but they are not so intuitive and not so easy to initialize. So often a sparse matrix is initially created in COO or LIL format (where we can efficiently add elements to the sparse matrix data), and then converted to CSC or CSR before used in real calcalations.\n",
    "\n",
    "When we create a sparse matrix we have to choose which format it should be stored in. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, lil_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dense matrix\n",
    "M = np.array([[1,0,0,0], [0,3,0,0], [0,1,1,0], [1,0,0,1]]); M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert from dense to sparse\n",
    "A = csr_matrix(M); A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert from sparse to dense\n",
    "A.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More efficient way to create sparse matrices: create an empty matrix and populate with using matrix indexing (avoids creating a potentially large dense matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = lil_matrix((4,4)) # empty 4x4 sparse matrix\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A[0,0] = 1\n",
    "A[1,1] = 3\n",
    "A[2,2] = A[2,1] = 1\n",
    "A[3,3] = A[3,0] = 1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between different sparse matrix formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = csr_matrix(A); A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = csc_matrix(A); A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute with sparse matrices like with dense matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(A * A).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.dot(A).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = np.array([1,2,3,4])[:,np.newaxis]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sparse matrix - dense vector multiplication\n",
    "A * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same result with dense matrix - dense vector multiplcation\n",
    "A.todense() * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Optimization (finding minima or maxima of a function) is a large field in mathematics, and optimization of complicated functions or in many variables can be rather involved. Here we will only look at a few very simple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a minima\n",
    "\n",
    "Let's first look at how to find the minima of a simple function of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4*x**3 + (x-2)**2 + x**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-5, 3, 100)\n",
    "ax.plot(x, f(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `fmin_bfgs` function to find the minima of a function. This function implements the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm, an iterative method for solving unconstrained nonlinear optimization problems.\n",
    "\n",
    "The BFGS method approximates Newton's method, a class of hill-climbing optimization techniques that seeks a stationary point of a (preferably twice continuously differentiable) function, but unlike Newton's method it does not require the specification of any of the function's derivatives.\n",
    "\n",
    "Since it is a hill-climbing (descending) algorithm, it will find local optima only, so for the example above, the optimization will yield a different result depending on where the algorithm is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_min = optimize.fmin_bfgs(f, -2)\n",
    "x_min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fmin_bfgs(f, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a suite of optimization algorithms, including the `brent` and `fminbound` functions. Each has a slightly different syntax, and use different algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.brent(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fminbound(f, -4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a solution to a function\n",
    "\n",
    "To find the solution (root) for a function of the form $f(x) = 0$ we can use the `fsolve` function. It requires an initial guess: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "omega_c = 3.0\n",
    "\n",
    "def f(omega):\n",
    "    # a transcendental equation: resonance frequencies of a low-Q SQUID terminated microwave resonator\n",
    "    return np.tan(2*np.pi*omega) - omega_c/omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "x = np.linspace(0, 3, 1000)\n",
    "y = f(x)\n",
    "mask = np.where(abs(y) > 50)\n",
    "x[mask] = y[mask] = None # get rid of vertical line when the function flip sign\n",
    "ax.plot(x, y)\n",
    "ax.plot([0, 3], [0, 0], 'k')\n",
    "ax.set_ylim(-5,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fsolve(f, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fsolve(f, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fsolve(f, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: truncated distribution\n",
    "\n",
    "Suppose that we observe $Y$ truncated below at $a$ (where $a$ is known). If $X$ is the distribution of our observation, then:\n",
    "\n",
    "$$ P(X \\le x) = P(Y \\le x|Y \\gt a) = \\frac{P(a \\lt Y \\le x)}{P(Y \\gt a)}$$\n",
    "\n",
    "(so, $Y$ is the original variable and $X$ is the truncated variable) \n",
    "\n",
    "Then X has the density:\n",
    "\n",
    "$$f_X(x) = \\frac{f_Y (x)}{1−F_Y (a)} \\, \\text{for} \\, x \\gt a$$ \n",
    "\n",
    "Suppose $Y \\sim N(\\mu, \\sigma^2)$ and $x_1,\\ldots,x_n$ are independent observations of $X$. We can use maximum likelihood to find $\\mu$ and $\\sigma$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can simulate a truncated distribution using a `while` statement to eliminate samples that are outside the support of the truncated distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.normal(size=10000)\n",
    "a = -1\n",
    "x_small = x < a\n",
    "\n",
    "while x_small.sum():\n",
    "    x[x_small] = np.random.normal(size=x_small.sum())\n",
    "    x_small = x < a\n",
    "    \n",
    "_ = plt.hist(x, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct a log likelihood for this function using the conditional form:\n",
    "\n",
    "$$f_X(x) = \\frac{f_Y (x)}{1−F_Y (a)} \\, \\text{for} \\, x \\gt a$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "trunc_norm = lambda theta, a, x: -(np.log(norm.pdf(x, theta[0], theta[1])) - \n",
    "                                      np.log(1 - norm.cdf(a, theta[0], theta[1]))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use another optimization algorithm, the **Nelder-Mead simplex algorithm**. It has a couple of advantages: \n",
    "\n",
    "- it does not require derivatives\n",
    "- it can optimize (minimize) a vector of parameters\n",
    "\n",
    "SciPy implements this algorithm in its `fmin` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin\n",
    "\n",
    "fmin(trunc_norm, np.array([1,2]), args=(-1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "Interpolation is simple and convenient in scipy: The `interp1d` function, when given arrays describing X and Y data, returns and object that behaves like a function that can be called for an arbitrary value of x (in the range covered by X), and it returns the corresponding interpolated y value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = np.arange(0, 10)  \n",
    "x = np.linspace(0, 9, 100)\n",
    "\n",
    "# simulate measurement with noise\n",
    "y_meas = f(n) + 0.1 * np.random.randn(len(n)) \n",
    "\n",
    "# Actual function\n",
    "y_real = f(x)\n",
    "\n",
    "linear_interpolation = interp1d(n, y_meas)\n",
    "y_interp1 = linear_interpolation(x)\n",
    "\n",
    "cubic_interpolation = interp1d(n, y_meas, kind='cubic')\n",
    "y_interp2 = cubic_interpolation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(n, y_meas, 'bs', label='noisy data')\n",
    "ax.plot(x, y_real, 'k', lw=2, label='true function')\n",
    "ax.plot(x, y_interp1, 'r', label='linear interp')\n",
    "ax.plot(x, y_interp2, 'g', label='cubic interp')\n",
    "ax.legend(loc=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "The `scipy.stats` module contains a large number of statistical distributions, statistical functions and tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = stats.poisson(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = np.arange(0,15)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "# plot the probability mass function (PMF)\n",
    "axes[0].step(n, X.pmf(n))\n",
    "\n",
    "# plot the commulative distribution function (CDF)\n",
    "axes[1].step(n, X.cdf(n))\n",
    "\n",
    "# plot histogram of 1000 random realizations of the stochastic variable X\n",
    "axes[2].hist(X.rvs(size=1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = stats.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "# plot the probability distribution function (PDF)\n",
    "axes[0].plot(x, Y.pdf(x))\n",
    "\n",
    "# plot the commulative distributin function (CDF)\n",
    "axes[1].plot(x, Y.cdf(x));\n",
    "\n",
    "# plot histogram of 1000 random realizations of the stochastic variable Y\n",
    "axes[2].hist(Y.rvs(size=1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Scientific Python Lecture Notes](http://scipy-lectures.github.io)\n",
    "\n",
    "[Official SciPy Tutorial](http://docs.scipy.org/doc/scipy/reference/tutorial/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
